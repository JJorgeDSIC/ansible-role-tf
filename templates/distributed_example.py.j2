import tensorflow as tf
import numpy as np
import os
import time
import sys

from tensorflow.examples.tutorials.mnist import input_data

parameter_servers =  {{ lookup('sequence', 'start=0 count={{ ps_nodes }} format=ps-%d:2222', wantlist=True) }}
workers = {{ lookup('sequence', 'start={{ ps_nodes }} count={{ ps_nodes + worker_nodes - 1 }} format=worker-%d:2222', wantlist=True) }}

{% if ansible_hostname.startswith("worker") %}
task_index = {{ ansible_hostname[-1] | int}} - {{ ps_nodes }}
job_name = "worker"
{% else %}
task_index = {{ ansible_hostname[-1] | int}}
job_name = "ps"
{% endif %}

cluster = tf.train.ClusterSpec({"ps":parameter_servers, "worker":workers})

"""
cluster = tf.train.ClusterSpec({
        'ps':['localhost:2222'],
        'worker':['localhost:2223']
})


job_name = sys.argv[1]
task_index = int(sys.argv[2])
"""

log_dir = '/logdir'

if job_name == "ps":

    server = tf.train.Server(cluster,job_name="ps",task_index=task_index)
    print("Starting parameter server, task={:}...".format(task_index))
    server.join()

elif job_name == "worker":

    print("Starting worker, task={:}...".format(task_index))

    is_chief = (task_index == 0)
    #with tf.device(tf.train.replica_device_setter(worker_device="/job:worker/task:%d" % task_index, cluster=cluster)):
    server = tf.train.Server(cluster,job_name="worker",task_index=task_index)


    DATA_PATH = "../DATASETS/"
    mnist = input_data.read_data_sets(DATA_PATH + "MNIST_TF/", one_hot=True)


    X_TOTAL = mnist.train.images.shape[0]
    X_DIM = mnist.train.images.shape[1]
    Y_DIM = mnist.train.labels.shape[1]
    print("# samples {}".format(X_TOTAL))
    print("Input's dimension {}".format(X_DIM))
    print("Label's dimension {}".format(Y_DIM))

    with tf.device('/job:worker/task:%d'%task_index):

        #Determining data's input (Setting to None first dimension allows us to use a variable batch size)
        images_placeholder = tf.placeholder(tf.float32, shape=(None, X_DIM))
        labels_placeholder = tf.placeholder(tf.int32, shape=(None, Y_DIM))
        learning_rate_placeholder = tf.placeholder(tf.float32)
        is_training_placeholder = tf.placeholder(tf.bool)

        #Defining a model
        def model_dropout(images, is_training=True):
            
            h1 = tf.layers.dense(inputs=images, units=1024, activation=tf.nn.relu)
            h1_dropout = tf.layers.dropout(inputs=h1, rate=0.5, training=is_training)

            h2 = tf.layers.dense(inputs=h1_dropout, units=1024, activation=tf.nn.relu)
            h2_dropout = tf.layers.dropout(inputs=h2, rate=0.5, training=is_training)

            h3 = tf.layers.dense(inputs=h2_dropout, units=1024, activation=tf.nn.relu)
            h3_dropout = tf.layers.dropout(inputs=h3, rate=0.5, training=is_training)

            logits = tf.layers.dense(inputs=h3_dropout, units=10, activation=None)

            return logits


        output_logits=model_dropout(images_placeholder, is_training_placeholder)

        cross_entropy = tf.reduce_mean(
            tf.nn.softmax_cross_entropy_with_logits(labels=labels_placeholder, logits=output_logits))

        train_step = tf.train.GradientDescentOptimizer(learning_rate_placeholder).minimize(cross_entropy)

        #Obtaining accuracy
        y_pred = tf.argmax(input=output_logits, axis=1)
        y_true = tf.argmax(input=labels_placeholder, axis=1)

        correct_prediction = tf.equal(y_pred, y_true)

        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        # Parameters
        LEARNING_RATE = 0.5
        BATCH_SIZE = 64
        EPOCHS = 10
        TOTAL_BATCHES = int(X_TOTAL/BATCH_SIZE)

        X_TOTAL_VALID = mnist.validation.images.shape[0]
        BATCH_SIZE_VAL = 100
        TOTAL_BATCHES_VALIDATION = int(X_TOTAL_VALID/BATCH_SIZE_VAL)

        # Initializing the variables
        #init = tf.global_variables_initializer()

        #A Session with a "with" block. The Session closes automatically at the end of the with block.
        
        training_acc = []
        validation_acc = []

    # Session
    # Supervisor
    sv = tf.train.Supervisor(logdir=os.getcwd()+log_dir,is_chief=is_chief,save_model_secs=30)
    sess = sv.prepare_or_wait_for_session(server.target)

    
    for epoch in range(EPOCHS):

        if sv.should_stop(): 
            break    
        
        batch_indexes = np.random.permutation(TOTAL_BATCHES)
        
        training_total_acc = 0
        start_time = time.time()
        
        for minibatch_number, batch_index in enumerate(batch_indexes):
            
            
            
            X_minibatch = mnist.train.images[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]
            Y_minibatch = mnist.train.labels[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]

            _, minibatch_acc = sess.run([train_step, accuracy], 
                              feed_dict={
                                  images_placeholder: X_minibatch,
                                  labels_placeholder: Y_minibatch,
                                  learning_rate_placeholder: LEARNING_RATE,
                                  is_training_placeholder: True
                              })
            
            training_total_acc+=minibatch_acc
            
            if minibatch_number % 500 == 0:
                print("MB INDEX {}".format(minibatch_number))
        
        print("E {} | TRAINING ACC: {:.4f} | TIME {:.2f} secs".format(epoch, training_total_acc/TOTAL_BATCHES, time.time() - start_time))
        
        training_acc.append(training_total_acc/TOTAL_BATCHES)
        
        total_minibatch_acc_val = 0
        
        start_time_val = time.time()
        
        for minibatch_number_validation in range(TOTAL_BATCHES_VALIDATION):
            
            X_minibatch = mnist.validation.images[minibatch_number_validation*BATCH_SIZE_VAL:(minibatch_number_validation+1)*BATCH_SIZE_VAL]
            Y_minibatch = mnist.validation.labels[minibatch_number_validation*BATCH_SIZE_VAL:(minibatch_number_validation+1)*BATCH_SIZE_VAL]

            minibatch_acc_val = sess.run(accuracy, 
                              feed_dict={
                                  images_placeholder: X_minibatch,
                                  labels_placeholder: Y_minibatch,
                                  is_training_placeholder: False
                              })
            
            total_minibatch_acc_val+=minibatch_acc_val

        print("E {} | VALIDATION ACC: {:.4f} | TIME {:.2f} secs".format(epoch, total_minibatch_acc_val/TOTAL_BATCHES_VALIDATION, time.time() - start_time_val))
        
        validation_acc.append(total_minibatch_acc_val/TOTAL_BATCHES_VALIDATION)

    print("Optimization Finished!")
